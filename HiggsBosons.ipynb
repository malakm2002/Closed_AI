{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2yNCR504X1Al"
      },
      "outputs": [],
      "source": [
        "# needed librairies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, precision_recall_curve\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UKkmkmlO3v2"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VltNZxjiO8n6",
        "outputId": "4453d9fb-309e-4872-c9b9-34a5420e107a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Malak\\AppData\\Local\\Temp\\ipykernel_17004\\237186723.py:1: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('HIGGS_train.csv', dtype={'8': float, '21': float})\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('HIGGS_train.csv', dtype={'8': float, '21': float})\n",
        "\n",
        "# define the headers of the dataset\n",
        "column_names = ['class_label', 'lepton_pt', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude', 'missing_energy_phi',\n",
        "                'jet_1_pt', 'jet_1_eta', 'jet_1_phi', 'jet_1_btag', 'jet_2_pt', 'jet_2_eta', 'jet_2_phi', 'jet_2_btag',\n",
        "                'jet_3_pt', 'jet_3_eta', 'jet_3_phi', 'jet_3_btag', 'jet_4_pt', 'jet_4_eta', 'jet_4_phi', 'jet_4_btag',\n",
        "                'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
        "\n",
        "# assign the headers to the data\n",
        "data.columns=column_names\n",
        "\n",
        "cleaned_data = data.copy();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke4ls9x0PkcZ"
      },
      "source": [
        "**Exploring Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTVuRozqvrA3",
        "outputId": "4373fa44-56f9-46e4-bcfc-ffc15d136c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first few rows:\n",
            "\n",
            "   class_label  lepton_pt  lepton_eta  lepton_phi  missing_energy_magnitude   \n",
            "0          1.0      0.908       0.329     0.35900                     1.500  \\\n",
            "1          1.0      0.799       1.470    -1.64000                     0.454   \n",
            "2          0.0      1.340      -0.877     0.93600                     1.990   \n",
            "3          1.0      1.110       0.321     1.52000                     0.883   \n",
            "4          0.0      1.600      -0.608     0.00707                     1.820   \n",
            "\n",
            "   missing_energy_phi  jet_1_pt  jet_1_eta jet_1_phi  jet_1_btag  ...   \n",
            "0              -0.313     1.100     -0.558     -1.59        2.17  ...  \\\n",
            "1               0.426     1.100      1.280      1.38        0.00  ...   \n",
            "2               0.882     1.790     -1.650    -0.942        0.00  ...   \n",
            "3              -1.210     0.681     -1.070    -0.922        0.00  ...   \n",
            "4              -0.112     0.848     -0.566      1.58        2.17  ...   \n",
            "\n",
            "   jet_4_eta  jet_4_phi  jet_4_btag   m_jj  m_jjj   m_lv  m_jlv   m_bb  m_wbb   \n",
            "0     -1.140  -0.000819         0.0  0.302  0.833  0.986  0.978  0.780  0.992  \\\n",
            "1      1.130   0.900000         0.0  0.910  1.110  0.986  0.951  0.803  0.866   \n",
            "2     -0.678  -1.360000         0.0  0.947  1.030  0.999  0.728  0.869  1.030   \n",
            "3     -0.374   0.113000         0.0  0.756  1.360  0.987  0.838  1.130  0.872   \n",
            "4     -0.654  -1.270000         3.1  0.824  0.938  0.972  0.789  0.431  0.961   \n",
            "\n",
            "   m_wwbb  \n",
            "0   0.798  \n",
            "1   0.780  \n",
            "2   0.958  \n",
            "3   0.808  \n",
            "4   0.958  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "\n",
            "\n",
            "Data Information:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 599999 entries, 0 to 599998\n",
            "Data columns (total 29 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   class_label               599999 non-null  float64\n",
            " 1   lepton_pt                 599999 non-null  float64\n",
            " 2   lepton_eta                599999 non-null  float64\n",
            " 3   lepton_phi                599999 non-null  float64\n",
            " 4   missing_energy_magnitude  599999 non-null  float64\n",
            " 5   missing_energy_phi        599999 non-null  float64\n",
            " 6   jet_1_pt                  599999 non-null  float64\n",
            " 7   jet_1_eta                 599999 non-null  float64\n",
            " 8   jet_1_phi                 599999 non-null  object \n",
            " 9   jet_1_btag                599999 non-null  float64\n",
            " 10  jet_2_pt                  599999 non-null  float64\n",
            " 11  jet_2_eta                 599999 non-null  float64\n",
            " 12  jet_2_phi                 599999 non-null  float64\n",
            " 13  jet_2_btag                599999 non-null  float64\n",
            " 14  jet_3_pt                  599999 non-null  float64\n",
            " 15  jet_3_eta                 599999 non-null  float64\n",
            " 16  jet_3_phi                 599999 non-null  float64\n",
            " 17  jet_3_btag                599998 non-null  float64\n",
            " 18  jet_4_pt                  599999 non-null  float64\n",
            " 19  jet_4_eta                 599999 non-null  float64\n",
            " 20  jet_4_phi                 599999 non-null  float64\n",
            " 21  jet_4_btag                599999 non-null  object \n",
            " 22  m_jj                      599999 non-null  float64\n",
            " 23  m_jjj                     599999 non-null  float64\n",
            " 24  m_lv                      599999 non-null  float64\n",
            " 25  m_jlv                     599999 non-null  float64\n",
            " 26  m_bb                      599999 non-null  float64\n",
            " 27  m_wbb                     599999 non-null  float64\n",
            " 28  m_wwbb                    599999 non-null  float64\n",
            "dtypes: float64(27), object(2)\n",
            "memory usage: 132.8+ MB\n",
            "None\n",
            "\n",
            "\n",
            "Data Statistics:\n",
            "\n",
            "         class_label      lepton_pt     lepton_eta     lepton_phi   \n",
            "count  599999.000000  599999.000000  599999.000000  599999.000000  \\\n",
            "mean        0.529286       0.992486      -0.000111       0.000166   \n",
            "std         0.499142       0.565045       1.007858       1.005480   \n",
            "min         0.000000       0.275000      -2.430000      -1.740000   \n",
            "25%         0.000000       0.591000      -0.737000      -0.870000   \n",
            "50%         1.000000       0.854000      -0.001030       0.002640   \n",
            "75%         1.000000       1.240000       0.738000       0.870000   \n",
            "max         1.000000       8.710000       2.430000       1.740000   \n",
            "\n",
            "       missing_energy_magnitude  missing_energy_phi       jet_1_pt   \n",
            "count             599999.000000       599999.000000  599999.000000  \\\n",
            "mean                   0.998020           -0.001155       0.990147   \n",
            "std                    0.599282            1.006755       0.474626   \n",
            "min                    0.000626           -1.740000       0.139000   \n",
            "25%                    0.577000           -0.873000       0.679000   \n",
            "50%                    0.891000           -0.001920       0.894000   \n",
            "75%                    1.290000            0.872000       1.170000   \n",
            "max                    9.900000            1.740000       8.380000   \n",
            "\n",
            "           jet_1_eta     jet_1_btag       jet_2_pt  ...       jet_4_pt   \n",
            "count  599999.000000  599999.000000  599999.000000  ...  599999.000000  \\\n",
            "mean       -0.002192       1.000382       0.992592  ...       0.986216   \n",
            "std         1.010297       1.026463       0.500731  ...       0.505671   \n",
            "min        -2.970000       0.000000       0.189000  ...       0.365000   \n",
            "25%        -0.689000       0.000000       0.656000  ...       0.618000   \n",
            "50%        -0.003000       1.090000       0.890000  ...       0.868000   \n",
            "75%         0.685000       2.170000       1.200000  ...       1.220000   \n",
            "max         2.970000       2.170000      11.600000  ...      11.600000   \n",
            "\n",
            "           jet_4_eta      jet_4_phi           m_jj          m_jjj   \n",
            "count  599999.000000  599999.000000  599999.000000  599999.000000  \\\n",
            "mean       -0.000308      -0.002128       1.034047       1.024418   \n",
            "std         1.008151       1.005564       0.669432       0.378086   \n",
            "min        -2.500000      -1.740000       0.107000       0.245000   \n",
            "25%        -0.715000      -0.872000       0.791000       0.846000   \n",
            "50%        -0.000461      -0.005810       0.895000       0.950000   \n",
            "75%         0.715000       0.868000       1.020000       1.080000   \n",
            "max         2.500000       1.740000      22.300000      11.600000   \n",
            "\n",
            "                m_lv          m_jlv           m_bb          m_wbb   \n",
            "count  599999.000000  599999.000000  599999.000000  599999.000000  \\\n",
            "mean        1.050635       1.010130       0.973342       1.033155   \n",
            "std         0.164443       0.398453       0.524886       0.364497   \n",
            "min         0.092200       0.157000       0.048100       0.303000   \n",
            "25%         0.986000       0.768000       0.674000       0.819000   \n",
            "50%         0.990000       0.917000       0.873000       0.947000   \n",
            "75%         1.020000       1.140000       1.140000       1.140000   \n",
            "max         5.920000      10.500000      13.700000       8.430000   \n",
            "\n",
            "              m_wwbb  \n",
            "count  599999.000000  \n",
            "mean        0.959835  \n",
            "std         0.313074  \n",
            "min         0.351000  \n",
            "25%         0.770000  \n",
            "50%         0.872000  \n",
            "75%         1.060000  \n",
            "max         6.260000  \n",
            "\n",
            "[8 rows x 27 columns]\n",
            "\n",
            "\n",
            "Data Shape:\n",
            "\n",
            "(599999, 29)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check the first few rows of the data\n",
        "print(\"The first few rows:\\n\")\n",
        "print(data.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# retrive the information of the data\n",
        "print(\"Data Information:\\n\")\n",
        "print(data.info())\n",
        "print(\"\\n\")\n",
        "\n",
        "# retrive basic statistics about the data\n",
        "print(\"Data Statistics:\\n\")\n",
        "print(data.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "# retrive the shape of the data\n",
        "print(\"Data Shape:\\n\")\n",
        "print(data.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# X = df.iloc[:, 1:]  # Select all columns except the first one as features\n",
        "# y = df.iloc[:, 0]   # Select the first column as the target variable\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rtShkKEUxng",
        "outputId": "3343dcc1-1486-4703-d6cb-807c3fc8cfe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column 8: \n",
            "[-1.59 1.38 -0.942 ... '3.50E-01' '-6.59E-03' '\"1.01\"']\n",
            "2312\n",
            "Column 21: \n",
            "[0.0 3.1 1.55 '0.00E+00' '3.10E+00' '1.55E+00' 'error' 's']\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# the columns 8 and 21 are of type objects: string\n",
        "# the values of these columns will be checked, \n",
        "# looking for unexpected values that lead to having mixed data types\n",
        "\n",
        "# column 8\n",
        "print(\"Column 8: \")\n",
        "print(cleaned_data['jet_1_phi'].unique())\n",
        "# result: \n",
        "  # 1. float64 numeric values in string objects\n",
        "  # 2. float64 numeric values in string objects and stored in a string object\n",
        "\n",
        "# solution:\n",
        "cleaned_data['jet_1_phi']=pd.to_numeric(cleaned_data['jet_1_phi'],errors='coerce')\n",
        "print(cleaned_data['jet_1_phi'].unique().size)\n",
        "\n",
        "# column 21\n",
        "print(\"Column 21: \")\n",
        "print(cleaned_data['jet_4_btag'].unique())\n",
        "# result:\n",
        "  # 1. float64 numeric values in string objects instead of float64 type\n",
        "  # 2. alphabetical values in string objects\n",
        "\n",
        "#solution:\n",
        "cleaned_data['jet_4_btag']=pd.to_numeric(cleaned_data['jet_4_btag'], errors='coerce')\n",
        "print(cleaned_data['jet_4_btag'].unique().size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cERkTjIlSqqN"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x7hKsArStu0"
      },
      "outputs": [],
      "source": [
        "# remove the training examples with NaN values from the dataset\n",
        "cleaned_data.dropna(inplace=True)\n",
        "\n",
        "# testing the realtime\n",
        "\n",
        "# the cleaned dataset will be saved to a new CSV file\n",
        "cleaned_data.to_csv('HIGGS_train_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LyEIlbGvv32"
      },
      "outputs": [],
      "source": [
        "# # Create a linear regression model and fit it to the training set\n",
        "# model = LinearRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Use the model to make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model's mean squared error\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# print('Mean Squared Error: {:.2f}'.format(mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ_3iODhzFJv"
      },
      "outputs": [],
      "source": [
        "# # Create a logistic regression model and fit it to the training set\n",
        "# model = LogisticRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Use the model to make predictions on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model's accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print('Accuracy: {:.2f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "KTkhdAXex1vA",
        "outputId": "0a10b4b8-f34e-41fd-c1f2-febcbfa45019"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-011c80d8cced>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Evaluate the classifier's accuracy on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m    425\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             if issparse(X) and (\n\u001b[1;32m    394\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "# # Load data\n",
        "# X = data.drop('class_label', axis=1)\n",
        "# y = data['class_label']\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Create a decision tree classifier and fit it to the training set\n",
        "# clf = DecisionTreeClassifier(random_state=42)\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate the classifier's accuracy on the test set\n",
        "# accuracy = clf.score(X_test, y_test)\n",
        "# print('Accuracy:', accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
